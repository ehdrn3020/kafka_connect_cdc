# S3 Confluent Connector
<br/>


### S3 버킷 생성
```
bucket name = kafka-sink-data
```
<br/>


### 커넥터 플러그인 다운로드
```
# confluent hub 설치
cd ~
curl -O https://packages.confluent.io/archive/7.9/confluent-7.9.1.tar.gz
tar xzf confluent-7.9.1.tar.gz

# confluent hub 설치 확인
./confluent-7.9.1/bin/confluent version

# s3 plugin 설치
./confluent-7.9.1/bin/confluent-hub install confluentinc/kafka-connect-s3:10.6.6
>>>
Do you want to update all detected configs? (yN) n
Do you want to update 1? (yN) n
Do you want to update 2? (yN) n
Do you want to update 3? (yN) n
Do you want to update 4? (yN) n

# 설치 확인
ls /home/ec2-user/confluent-7.9.1/share/confluent-hub-components/confluentinc-kafka-connect-s3/lib

# 환경변수 설정 (선택)
export CONFLUENT_HOME=~/kafka_2.13-3.5.0/confluent-7.9.1
export PATH=$PATH:$CONFLUENT_HOME/bin
```
설치 참조 
- https://docs.confluent.io/platform/current/installation/installing_cp/zip-tar.html
<br/>


### 플러그인 검색
어떤 plugin을 confluent에서 설치할 수 있는지 검색가능
- https://www.confluent.io/hub/
<br/>


### 커넥터 설정파일 생성
```
cd kafka_2.13-3.5.0/

vi config/connect-s3-sink.properties
{
  "name": "s3-sink-connector",
  "config": {
    "connector.class": "io.confluent.connect.s3.S3SinkConnector",
    "tasks.max": "5",
    "topics": "orders",
    "s3.bucket.name": "kafka-sink-data",
    "s3.region": "ap-northeast-2",
    "storage.class": "io.confluent.connect.s3.storage.S3Storage",
    "aws.access.key.id": "${}",
    "aws.secret.access.key": "${}",
    "key.converter": "org.apache.kafka.connect.converters.ByteArrayConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "partitioner.class": "io.confluent.connect.storage.partitioner.DefaultPartitioner",
    "partition.field.name": "order_id",
    "format.class": "io.confluent.connect.s3.format.json.JsonFormat",
    "flush.size": "3",
    "store.kafka.keys": "true",
    "key.format.class": "io.confluent.connect.s3.format.json.JsonFormat"
  }
}

{
  "name": "s3-sink-connector",
  "config": {
    "connector.class": "io.confluent.connect.s3.S3SinkConnector",
    "tasks.max": "1",
    "topics": "orders",
    "s3.bucket.name": "kafka-sink-data",
    "s3.region": "ap-northeast-2",
    "storage.class": "io.confluent.connect.s3.storage.S3Storage",
    "aws.access.key.id": "${}",
    "aws.secret.access.key": "${}",
    "format.class": "io.confluent.connect.s3.format.json.JsonFormat",
    "flush.size": "1",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",
    "key.converter": "org.apache.kafka.connect.json.JsonConverter",
    "key.converter.schemas.enable": "false",
    "partitioner.class": "io.confluent.connect.storage.partitioner.DefaultPartitioner",
    "rotate.schedule.interval.ms": "60000",
    "timezone": "Asia/Seoul"
  }
}
```
<br/>


## 커넥터 Path 설정
```
# 프로퍼티 파일 수정
vi config/connect-distributed.properties

# 해당 경로 추가
plugin.path=/home/ec2-user/confluent-7.9.1/share/confluent-hub-components
```
<br/>


### 커넥터 실행
```
# 커넥터 서비스 실행
./bin/connect-distributed.sh ./config/connect-distributed.properties

# 연동 플러그인 확인
curl localhost:8083/connector-plugins | jq
...
[
  {
    "class": "io.confluent.connect.s3.S3SinkConnector",
    "type": "sink",
    "version": "10.6.6"
  },
  ...
]
```
<br/>


### 커넥터 등록
```
# 동적 커넥터 등록
curl -X POST -H "Content-Type: application/json" --data @config/connect-s3-sink.properties http://localhost:8083/connectors

# 등록 확인
curl http://localhost:8083/connectors
["s3-sink-connector"]

# 등록 해지
curl -X DELETE http://localhost:8083/connectors/s3-sink-connector
```
<br/>


### 토픽생성
```
# 5개의 파티션으로 구성된 orders 토픽 생성
./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic orders --partitions 5 --replication-factor 1
```
<br/>


### 레코드 생성
```
# 토픽에 레코드 생성
./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic orders --property key.separator=:

>>> 데이터 입력
1:{"order_id": "1", "customer_id": "123", "book_id": "456", "quantity": 2, "price": 29.99, "order_date": "2023-10-01"}
2:{"order_id": "2", "customer_id": "124", "book_id": "457", "quantity": 1, "price": 15.99, "order_date": "2023-10-02"}
3:{"order_id": "3", "customer_id": "125", "book_id": "458", "quantity": 3, "price": 45.00, "order_date": "2023-10-03"}

# s3 확인
s3://kafka-sink-data/topics/orders/partition=0/orders+0+0000000000.json

# 저장 경로 구조
kafka-sink-data: S3 버킷 이름
topics: 기본 디렉토리 접두사
orders: Kafka 토픽 이름
partition=0: Kafka 파티션 번호
orders+0+0000000000.json: 파일명 형식 (토픽이름+파티션+오프셋.확장자)
```
<br/>